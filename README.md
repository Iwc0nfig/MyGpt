# MyGpt

MyGpt is a **from-scratch implementation of a GPT-style language model** in Python.  
The goal of this project is to learn and demonstrate the core building blocks behind large language models â€” tokenization, dataset preparation, transformer architecture, and text generation.

---

## ðŸš€ Features
- **Custom Tokenizer** â€” Simple yet effective tokenization implemented in `tokenizer.py`.
- **Data Preparation Pipeline** â€” Clean, preprocess, and encode datasets for training (`data_preparation.py`).
- **Transformer-based Model** â€” A minimal GPT-like architecture implemented from scratch in `model.py`.
- **Text Generation** â€” Use the trained model to generate coherent text sequences.
- **Educational Focus** â€” Code is written to be readable and easy to modify.

---
